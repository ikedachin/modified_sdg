{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7921182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 設定 ====\n",
    "BASE_URL = os.environ.get(\"OPENAI_BASE_URL\", \"https://q1dpsx0l6ec0hq-8000.proxy.runpod.net/v1\")  # 例: https://<id>-8000.proxy.runpod.net/v1\n",
    "API_KEY  = os.environ.get(\"OPENAI_API_KEY\", \"sk-xxxxx\")  # サーバーがAPIキー不要なら値は無視される\n",
    "MODEL    = os.environ.get(\"OPENAI_MODEL\", \"openai/gpt-oss-120b\") # サーバー側でロード済みのモデル名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cde6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "def chat_once(user_message: str) -> str:\n",
    "    \"\"\"非ストリーミングで1レスポンスを取得\"\"\"\n",
    "    url = f\"{BASE_URL}/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\",   \"content\": user_message},\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 256,\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=120)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.HTTPError as e:\n",
    "        print(f\"[HTTPError] {e} :: {getattr(e.response, 'text', None)}\", file=sys.stderr)\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\", file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "def chat_stream(user_message: str):\n",
    "    \"\"\"サーバー送信イベント（SSE）でトークンを逐次受信\"\"\"\n",
    "    url = f\"{BASE_URL}/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\",   \"content\": user_message},\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 256,\n",
    "        \"stream\": True,  # ストリーミング有効化\n",
    "        \"method\": \"POST\",\n",
    "    }\n",
    "    with requests.post(url, headers=HEADERS, data=json.dumps(payload), stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        for line in r.iter_lines(decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\"data: \"):\n",
    "                chunk = line[len(\"data: \"):]\n",
    "                if chunk.strip() == \"[DONE]\":\n",
    "                    break\n",
    "                try:\n",
    "                    obj = json.loads(chunk)\n",
    "                    delta = obj[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "                    if delta:\n",
    "                        print(delta, end=\"\", flush=True)\n",
    "                except Exception:\n",
    "                    # SSE以外の行はそのまま表示（必要に応じて無視）\n",
    "                    pass\n",
    "        print()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 使い方: python client.py \"こんにちは！\"\n",
    "#     question = sys.argv[1] if len(sys.argv) > 1 else \"自己紹介して\"\n",
    "#     print(\"=== Non-Streaming ===\")\n",
    "#     print(chat_once(question))\n",
    "#     print(\"\\n=== Streaming ===\")\n",
    "#     chat_stream(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeb6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Non-Streaming ===\n",
      "\n",
      "=== Streaming ===\n",
      "It looks like you’ve pasted the path to a Jupyter kernel‑connection file:\n",
      "\n",
      "```\n",
      "/Users/ikedashinji/Library/Jupyter/runtime/kernel‑v3a0a68368d4e8db63065a8eb024c005c69fe1fda2.json\n",
      "```\n",
      "\n",
      "That file contains the JSON‑encoded connection information (ports, IP, authentication key, etc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使い方: python client.py \"こんにちは！\"\n",
    "question = sys.argv[1] if len(sys.argv) > 1 else \"何か面白い話をしてください。日本語で500文字程度で出力してください。\"\n",
    "print(\"=== Non-Streaming ===\")\n",
    "# print(chat_once(question))\n",
    "print(\"\\n=== Streaming ===\")\n",
    "chat_stream(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c3537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
