今回は「BARE」について解説します。

BAREとは、Instructチューニングを施す前のBaseモデルを使い、「初期段階の質問データ」を自動生成する仕組みです。
BAREの最大の特長は、その\*\*「多様性」\*\*にあります。一般的なSFT済みのInstructモデルでは、生成されるデータの多様性が低下することが研究で報告されていますが、BAREはこれを克服するために開発された手法です。

以下に、BAREの要点を明確にまとめます。

### BAREの要点：

1. Baseモデルが、完全に自律的な形で多種多様なプロンプトを生成する。
2. YAMLなどの「出力書式」は基本的に維持しつつ、説明や指示の言い回しに関しては一定の範囲で変化を許容する。
3. 評価基準や自己レビューの詳細は含めない（これは次のRefineフェーズで処理する）。
4. 多様性を最大化するため、各サンプルごとに明確に異なるテーマ、視点、文体を用いるよう指示する。
5. 出力のランダム性と整合性を両立するために、**生成時の温度（temperature）は0.7前後**に設定する。
6. Baseモデルはシンプルな文章生成に適しているため、出力フォーマットの多少の乱れは許容する。また、基本的に\*\*BASE\_PROMPT（またはそれに類似する主要部分）\*\*のみを出力させる。

これらの条件を満たしたBaseモデルからは、以下のようなJSON形式のデータが生成されます。

### 出力フォーマット：

'''json
{"Question": "具体的な質問文1", "Answer": "質問に対する回答内容1"}
{"Question": "具体的な質問文2", "Answer": "質問に対する回答内容2"}
{"Question": "具体的な質問文3", "Answer": "質問に対する回答内容3"}
<stop>
'''

* 各データは「Question」「Answer」の2要素を含みます。

  * **Question**: 質問そのものを記載。
  * **Answer**: 質問に対するAIの回答を記載。

また、Baseモデルへの入力時に、何問分のデータを生成するかを事前に指定することができます。
生成データの最後には必ず`<stop>`タグが挿入されます（これは文章の終了を明示するEOSトークンのような役割です）。
また、出力される質問はモデルがほかの記憶なしに回答できるようになっています。（質問のみだけでAIが十分に回答できるようになっています。）

以下に、実際にBaseモデルから出力されたデータを提示します。
設定内容および出力データを確認し、特に以下の点に着目してください。

* **指定された質問数（今回は4問）が正しく生成されていること。**
* **質問同士に関連性が一切なく、多様であること。**
* **最後に必ず`<stop>`タグが挿入されていること。**

### 今回の出力設定：

* 出力質問数：4問
* 質問間の関連性：なし（多様な内容を重視）

---

以下が実際の出力データです。
それでは実際にベースモデルが出力してきた質問分野がまったくバラバラな4つの質問データを見てきましょう。
これは、あくまでモデルが直接出してきたjson形式のデータです。（<stop>タグもついています。）

## 出力データ(json形式 & <stop>タグ付き)
```json